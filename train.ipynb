{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorge-jrzz/UEA-ML_SRCNN/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJMFykOgtTzv",
        "outputId": "5667f205-f191-40c5-ccdb-1e57a7d9a20d"
      },
      "outputs": [],
      "source": [
        "#@title # Instalación de dependencias\n",
        "!wget https://raw.githubusercontent.com/jorge-jrzz/UEA-ML_SRCNN/refs/heads/main/install_datasets.py\n",
        "!wget https://raw.githubusercontent.com/jorge-jrzz/UEA-ML_SRCNN/refs/heads/main/requirements.txt\n",
        "%pip install -r requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pUd2T44trBj",
        "outputId": "87beada8-5577-43c7-e643-824dea0b89d2"
      },
      "outputs": [],
      "source": [
        "#@markdown Esto descarga los datasets desde kaggle necesarios para el modelo.\n",
        "from install_datasets import download_datasets\n",
        "download_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBphB5sR4eNz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puvKJ7kK4mus"
      },
      "outputs": [],
      "source": [
        "# Directorios de los datasets (ajusta las rutas según tu sistema)\n",
        "DIV2K_TRAIN_DIR = './DIV2K/DIV2K_train_HR'  # Carpeta con imágenes HR de DIV2K (train)\n",
        "DIV2K_VALID_DIR = './DIV2K/DIV2K_valid_HR'  # Carpeta con imágenes HR de DIV2K (valid)\n",
        "SET5_DIR = './Set5'                         # Carpeta con imágenes HR de Set5\n",
        "\n",
        "# Parámetros\n",
        "SCALE_FACTOR = 2  # Factor de escala para superresolución (2x)\n",
        "PATCH_SIZE_LR = 16  # Tamaño del parche LR (16x16)\n",
        "PATCH_SIZE_HR = PATCH_SIZE_LR * SCALE_FACTOR  # Tamaño del parche HR (32x32)\n",
        "BATCH_SIZE = 16  # Tamaño del batch para entrenamiento\n",
        "NUM_PATCHES_PER_IMAGE = 10  # Número de parches extraídos por imagen\n",
        "SUBSET_SIZE = 50  # Subconjunto de imágenes DIV2K para entrenamiento\n",
        "VALID_SUBSET_SIZE = 25  # Subconjunto de imágenes DIV2K para entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQdtDXbzuKwG"
      },
      "outputs": [],
      "source": [
        "# Transformaciones para aumento de datos\n",
        "data_augmentation = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(degrees=(90, 90)),  # Rotaciones de 90°\n",
        "    transforms.RandomRotation(degrees=(180, 180)),  # Rotaciones de 180°\n",
        "])\n",
        "\n",
        "# Función para downsampling (crear imagen LR desde HR)\n",
        "def create_lr_image(hr_image, scale_factor):\n",
        "    \"\"\"Convierte una imagen HR a LR usando interpolación bicúbica.\"\"\"\n",
        "    h, w = hr_image.shape[:2]\n",
        "    new_h, new_w = h // scale_factor, w // scale_factor\n",
        "    lr_image = cv2.resize(hr_image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
        "    # Upscale de vuelta para que LR tenga el mismo tamaño que HR (para SRCNN)\n",
        "    lr_image = cv2.resize(lr_image, (w, h), interpolation=cv2.INTER_CUBIC)\n",
        "    return lr_image\n",
        "\n",
        "# Clase Dataset personalizada para DIV2K y Set5\n",
        "class SuperResolutionDataset(Dataset):\n",
        "    def __init__(self, hr_dir, is_train=True, subset_size=None):\n",
        "        \"\"\"Inicializa el dataset.\"\"\"\n",
        "        self.hr_dir = hr_dir\n",
        "        self.is_train = is_train\n",
        "        self.image_paths = sorted([os.path.join(hr_dir, f) for f in os.listdir(hr_dir) if f.endswith('.png')])\n",
        "        if subset_size is not None and is_train:\n",
        "            self.image_paths = self.image_paths[:subset_size]  # Usar subconjunto para entrenamiento\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Número total de parches (imágenes * parches por imagen).\"\"\"\n",
        "        return len(self.image_paths) * NUM_PATCHES_PER_IMAGE if self.is_train else len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Devuelve un par de parches LR-HR (entrenamiento) o imagen completa (evaluación).\"\"\"\n",
        "        if self.is_train:\n",
        "            # Seleccionar imagen y parche\n",
        "            img_idx = idx // NUM_PATCHES_PER_IMAGE\n",
        "            patch_idx = idx % NUM_PATCHES_PER_IMAGE\n",
        "            img_path = self.image_paths[img_idx]\n",
        "        else:\n",
        "            img_path = self.image_paths[idx]\n",
        "\n",
        "        # Cargar imagen HR\n",
        "        hr_image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        hr_image = cv2.cvtColor(hr_image, cv2.COLOR_BGR2RGB)  # Convertir a RGB\n",
        "        hr_image = np.array(hr_image).astype(np.float32) / 255.0  # Normalizar a [0,1]\n",
        "\n",
        "        # Crear imagen LR\n",
        "        lr_image = create_lr_image(hr_image, SCALE_FACTOR)\n",
        "\n",
        "        if self.is_train:\n",
        "            # Extraer parche aleatorio\n",
        "            h, w = hr_image.shape[:2]\n",
        "            x = np.random.randint(0, w - PATCH_SIZE_HR)\n",
        "            y = np.random.randint(0, h - PATCH_SIZE_HR)\n",
        "            hr_patch = hr_image[y:y+PATCH_SIZE_HR, x:x+PATCH_SIZE_HR]\n",
        "            lr_patch = lr_image[y:y+PATCH_SIZE_HR, x:x+PATCH_SIZE_HR]\n",
        "\n",
        "            # Convertir a PIL para aumento de datos\n",
        "            hr_patch_pil = Image.fromarray((hr_patch * 255).astype(np.uint8))\n",
        "            lr_patch_pil = Image.fromarray((lr_patch * 255).astype(np.uint8))\n",
        "\n",
        "            # Aplicar aumento de datos\n",
        "            seed = np.random.randint(0, 10000)\n",
        "            torch.manual_seed(seed)\n",
        "            hr_patch_pil = data_augmentation(hr_patch_pil)\n",
        "            torch.manual_seed(seed)\n",
        "            lr_patch_pil = data_augmentation(lr_patch_pil)\n",
        "\n",
        "            # Convertir de vuelta a numpy\n",
        "            hr_patch = np.array(hr_patch_pil).astype(np.float32) / 255.0\n",
        "            lr_patch = np.array(lr_patch_pil).astype(np.float32) / 255.0\n",
        "\n",
        "            # Convertir a tensores\n",
        "            hr_patch = torch.from_numpy(hr_patch).permute(2, 0, 1)  # [C, H, W]\n",
        "            lr_patch = torch.from_numpy(lr_patch).permute(2, 0, 1)  # [C, H, W]\n",
        "\n",
        "            return lr_patch, hr_patch\n",
        "        else:\n",
        "            # Para evaluación, devolver imagen completa\n",
        "            hr_image = torch.from_numpy(hr_image).permute(2, 0, 1)\n",
        "            lr_image = torch.from_numpy(lr_image).permute(2, 0, 1)\n",
        "            return lr_image, hr_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjYyxTKu6DUl"
      },
      "outputs": [],
      "source": [
        "# Crear datasets\n",
        "train_dataset = SuperResolutionDataset(DIV2K_TRAIN_DIR, is_train=True, subset_size=SUBSET_SIZE)\n",
        "valid_dataset = SuperResolutionDataset(DIV2K_VALID_DIR, is_train=False, subset_size=VALID_SUBSET_SIZE)\n",
        "test_dataset = SuperResolutionDataset(SET5_DIR, is_train=False)\n",
        "\n",
        "# Crear dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xIjkrFh7Cmz"
      },
      "outputs": [],
      "source": [
        "# Definición del modelo SRCNN\n",
        "class SRCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SRCNN, self).__init__()\n",
        "        # Capa 1: Extracción de parches y representación\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, padding=4)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Capa 2: Mapeo no lineal\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=1, padding=0)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Capa 3: Reconstrucción\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=3, kernel_size=5, padding=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu1(self.conv1(x))\n",
        "        out = self.relu2(self.conv2(out))\n",
        "        out = self.conv3(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR3rKGdyupY0",
        "outputId": "d32520a9-5ff0-4e1d-feaa-2453d349f659"
      },
      "outputs": [],
      "source": [
        "# Inicializar modelo, función de pérdida y optimizador\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "model = SRCNN().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)  # Reducir LR cada 30 épocas\n",
        "\n",
        "# Función para entrenar el modelo\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for lr_batch, hr_batch in dataloader:\n",
        "        lr_batch, hr_batch = lr_batch.to(device), hr_batch.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(lr_batch)\n",
        "        loss = criterion(outputs, hr_batch)\n",
        "\n",
        "        # Backward pass y optimización\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "# Función para evaluar el modelo\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    psnr_val = 0\n",
        "    ssim_val = 0\n",
        "    with torch.no_grad():\n",
        "        for lr_batch, hr_batch in dataloader:\n",
        "            lr_batch, hr_batch = lr_batch.to(device), hr_batch.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(lr_batch)\n",
        "            loss = criterion(outputs, hr_batch)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # Calcular PSNR y SSIM\n",
        "            output_np = outputs.squeeze(0).permute(1, 2, 0).cpu().numpy().clip(0, 1)\n",
        "            target_np = hr_batch.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "            psnr_val += psnr(target_np, output_np, data_range=1.0)\n",
        "            ssim_val += ssim(target_np, output_np,\n",
        "                             data_range=1.0,\n",
        "                             win_size=3,  # Tamaño de ventana más pequeño (3x3)\n",
        "                             channel_axis=2)  # El eje 2 corresponde a los canales RGB\n",
        "\n",
        "    return epoch_loss / len(dataloader), psnr_val / len(dataloader), ssim_val / len(dataloader)\n",
        "\n",
        "# Función para guardar imágenes de ejemplo\n",
        "def save_example(model, dataloader, epoch, device, save_dir='./results'):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for lr_batch, hr_batch in dataloader:\n",
        "            lr_batch, hr_batch = lr_batch.to(device), hr_batch.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            sr_batch = model(lr_batch)\n",
        "\n",
        "            # Convertir a numpy para visualización\n",
        "            lr_img = lr_batch[0].permute(1, 2, 0).cpu().numpy().clip(0, 1)\n",
        "            hr_img = hr_batch[0].permute(1, 2, 0).cpu().numpy()\n",
        "            sr_img = sr_batch[0].permute(1, 2, 0).cpu().numpy().clip(0, 1)\n",
        "\n",
        "            # Calcular PSNR y SSIM\n",
        "            psnr_val = psnr(hr_img, sr_img, data_range=1.0)\n",
        "            ssim_val = ssim(hr_img, sr_img,\n",
        "                           data_range=1.0,\n",
        "                           win_size=3,  # Tamaño de ventana más pequeño\n",
        "                           channel_axis=2)  # El eje 2 corresponde a los canales RGB\n",
        "\n",
        "            # Crear figura\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "            axes[0].imshow(lr_img)\n",
        "            axes[0].set_title('LR Input')\n",
        "            axes[0].axis('off')\n",
        "\n",
        "            axes[1].imshow(sr_img)\n",
        "            axes[1].set_title(f'SR Output (PSNR: {psnr_val:.2f}, SSIM: {ssim_val:.4f})')\n",
        "            axes[1].axis('off')\n",
        "\n",
        "            axes[2].imshow(hr_img)\n",
        "            axes[2].set_title('HR Ground Truth')\n",
        "            axes[2].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'{save_dir}/epoch_{epoch}.png')\n",
        "            plt.close()\n",
        "\n",
        "            break  # Solo guardar una imagen\n",
        "\n",
        "# Entrenamiento principal\n",
        "def train_model(model, train_loader, valid_loader, test_loader, criterion, optimizer, scheduler,\n",
        "                num_epochs=100, device='cpu', save_dir='./checkpoints'):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    best_psnr = 0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_psnrs = []\n",
        "    val_ssims = []\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Entrenamiento\n",
        "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Validación\n",
        "        # Validar cada 5 épocas en lugar de cada época\n",
        "        if epoch % 5 == 0:\n",
        "            val_loss, val_psnr, val_ssim = evaluate(model, valid_loader, criterion, device)\n",
        "            val_losses.append(val_loss)\n",
        "            val_psnrs.append(val_psnr)\n",
        "            val_ssims.append(val_ssim)\n",
        "\n",
        "        # Actualizar learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        # Guardar el mejor modelo\n",
        "        if val_psnr > best_psnr:\n",
        "            best_psnr = val_psnr\n",
        "            torch.save(model.state_dict(), f'{save_dir}/best_model.pth')\n",
        "            print(f\"Epoch {epoch}: Mejor modelo guardado con PSNR {best_psnr:.2f}\")\n",
        "\n",
        "        # Guardar checkpoint cada 10 épocas\n",
        "        if epoch % 10 == 0:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'best_psnr': best_psnr\n",
        "            }, f'{save_dir}/checkpoint_epoch_{epoch}.pth')\n",
        "\n",
        "        # Guardar imagen de ejemplo cada 10 épocas\n",
        "        if epoch % 10 == 0:\n",
        "            save_example(model, test_loader, epoch, device)\n",
        "\n",
        "        # Imprimir estadísticas\n",
        "        time_taken = time.time() - start_time\n",
        "        print(f\"Época {epoch}/{num_epochs} - Tiempo: {time_taken:.2f}s - Train Loss: {train_loss:.6f} - \"\n",
        "              f\"Val Loss: {val_loss:.6f} - Val PSNR: {val_psnr:.2f} - Val SSIM: {val_ssim:.4f}\")\n",
        "\n",
        "    # Evaluar en el conjunto de prueba\n",
        "    test_loss, test_psnr, test_ssim = evaluate(model, test_loader, criterion, device)\n",
        "    print(f\"Resultados finales en test - Loss: {test_loss:.6f} - PSNR: {test_psnr:.2f} - SSIM: {test_ssim:.4f}\")\n",
        "\n",
        "    # Guardar gráficas de entrenamiento\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Val Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss vs. Epoch')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(val_psnrs, label='Val PSNR')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('PSNR (dB)')\n",
        "    plt.legend()\n",
        "    plt.title('PSNR vs. Epoch')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(val_ssims, label='Val SSIM')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('SSIM')\n",
        "    plt.legend()\n",
        "    plt.title('SSIM vs. Epoch')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{save_dir}/training_curves.png')\n",
        "    plt.close()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "i-60sTMWuuHJ",
        "outputId": "25ec8c5b-266c-423a-d766-9c1c85fea497"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 20\n",
        "SAVE_DIR = './srcnn_checkpoints'\n",
        "\n",
        "# Entrenar modelo\n",
        "trained_model = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    valid_loader=valid_loader,\n",
        "    test_loader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=device,\n",
        "    save_dir=SAVE_DIR\n",
        ")\n",
        "\n",
        "# Guardar modelo final\n",
        "torch.save(trained_model.state_dict(), f'{SAVE_DIR}/final_model.pth')\n",
        "print(f\"Modelo final guardado en {SAVE_DIR}/final_model.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPGchO8Sf8nUSYwCpuHg7lu",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
