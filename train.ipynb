{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPGchO8Sf8nUSYwCpuHg7lu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorge-jrzz/UEA-ML_SRCNN/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJMFykOgtTzv",
        "outputId": "5667f205-f191-40c5-ccdb-1e57a7d9a20d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m124.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title # Instalación de dependencias\n",
        "!pip install torch torchvision matplotlib kagglehub opencv-python numpy pillow scikit-image --quiet\n",
        "!wget https://raw.githubusercontent.com/jorge-jrzz/UEA-ML_SRCNN/refs/heads/main/install_datasets.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC5DbkUq873o",
        "outputId": "250655e2-2c68-483b-de91-a7c366565f5e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Esto descarga los datasets desde kaggle necesarios para el modelo.\n",
        "from install_datasets import download_datasets\n",
        "download_datasets()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pUd2T44trBj",
        "outputId": "87beada8-5577-43c7-e643-824dea0b89d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 Descargando dataset: Set5...\n",
            "📥 Descargando dataset: DIV2K...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr"
      ],
      "metadata": {
        "id": "ZBphB5sR4eNz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorios de los datasets (ajusta las rutas según tu sistema)\n",
        "DIV2K_TRAIN_DIR = './DIV2K/DIV2K_train_HR'  # Carpeta con imágenes HR de DIV2K (train)\n",
        "DIV2K_VALID_DIR = './DIV2K/DIV2K_valid_HR'  # Carpeta con imágenes HR de DIV2K (valid)\n",
        "SET5_DIR = './Set5'                         # Carpeta con imágenes HR de Set5\n",
        "\n",
        "# Parámetros\n",
        "SCALE_FACTOR = 2  # Factor de escala para superresolución (2x)\n",
        "PATCH_SIZE_LR = 16  # Tamaño del parche LR (16x16)\n",
        "PATCH_SIZE_HR = PATCH_SIZE_LR * SCALE_FACTOR  # Tamaño del parche HR (32x32)\n",
        "BATCH_SIZE = 16  # Tamaño del batch para entrenamiento\n",
        "NUM_PATCHES_PER_IMAGE = 10  # Número de parches extraídos por imagen\n",
        "SUBSET_SIZE = 100  # Subconjunto de imágenes DIV2K para entrenamiento\n",
        "VALID_SUBSET_SIZE = 50  # Subconjunto de imágenes DIV2K para entrenamiento"
      ],
      "metadata": {
        "id": "puvKJ7kK4mus"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones para aumento de datos\n",
        "data_augmentation = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(degrees=(90, 90)),  # Rotaciones de 90°\n",
        "    transforms.RandomRotation(degrees=(180, 180)),  # Rotaciones de 180°\n",
        "])\n",
        "\n",
        "# Función para downsampling (crear imagen LR desde HR)\n",
        "def create_lr_image(hr_image, scale_factor):\n",
        "    \"\"\"Convierte una imagen HR a LR usando interpolación bicúbica.\"\"\"\n",
        "    h, w = hr_image.shape[:2]\n",
        "    new_h, new_w = h // scale_factor, w // scale_factor\n",
        "    lr_image = cv2.resize(hr_image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
        "    # Upscale de vuelta para que LR tenga el mismo tamaño que HR (para SRCNN)\n",
        "    lr_image = cv2.resize(lr_image, (w, h), interpolation=cv2.INTER_CUBIC)\n",
        "    return lr_image\n",
        "\n",
        "# Clase Dataset personalizada para DIV2K y Set5\n",
        "class SuperResolutionDataset(Dataset):\n",
        "    def __init__(self, hr_dir, is_train=True, subset_size=None):\n",
        "        \"\"\"Inicializa el dataset.\"\"\"\n",
        "        self.hr_dir = hr_dir\n",
        "        self.is_train = is_train\n",
        "        self.image_paths = sorted([os.path.join(hr_dir, f) for f in os.listdir(hr_dir) if f.endswith('.png')])\n",
        "        if subset_size is not None and is_train:\n",
        "            self.image_paths = self.image_paths[:subset_size]  # Usar subconjunto para entrenamiento\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Número total de parches (imágenes * parches por imagen).\"\"\"\n",
        "        return len(self.image_paths) * NUM_PATCHES_PER_IMAGE if self.is_train else len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Devuelve un par de parches LR-HR (entrenamiento) o imagen completa (evaluación).\"\"\"\n",
        "        if self.is_train:\n",
        "            # Seleccionar imagen y parche\n",
        "            img_idx = idx // NUM_PATCHES_PER_IMAGE\n",
        "            patch_idx = idx % NUM_PATCHES_PER_IMAGE\n",
        "            img_path = self.image_paths[img_idx]\n",
        "        else:\n",
        "            img_path = self.image_paths[idx]\n",
        "\n",
        "        # Cargar imagen HR\n",
        "        hr_image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        hr_image = cv2.cvtColor(hr_image, cv2.COLOR_BGR2RGB)  # Convertir a RGB\n",
        "        hr_image = np.array(hr_image).astype(np.float32) / 255.0  # Normalizar a [0,1]\n",
        "\n",
        "        # Crear imagen LR\n",
        "        lr_image = create_lr_image(hr_image, SCALE_FACTOR)\n",
        "\n",
        "        if self.is_train:\n",
        "            # Extraer parche aleatorio\n",
        "            h, w = hr_image.shape[:2]\n",
        "            x = np.random.randint(0, w - PATCH_SIZE_HR)\n",
        "            y = np.random.randint(0, h - PATCH_SIZE_HR)\n",
        "            hr_patch = hr_image[y:y+PATCH_SIZE_HR, x:x+PATCH_SIZE_HR]\n",
        "            lr_patch = lr_image[y:y+PATCH_SIZE_HR, x:x+PATCH_SIZE_HR]\n",
        "\n",
        "            # Convertir a PIL para aumento de datos\n",
        "            hr_patch_pil = Image.fromarray((hr_patch * 255).astype(np.uint8))\n",
        "            lr_patch_pil = Image.fromarray((lr_patch * 255).astype(np.uint8))\n",
        "\n",
        "            # Aplicar aumento de datos\n",
        "            seed = np.random.randint(0, 10000)\n",
        "            torch.manual_seed(seed)\n",
        "            hr_patch_pil = data_augmentation(hr_patch_pil)\n",
        "            torch.manual_seed(seed)\n",
        "            lr_patch_pil = data_augmentation(lr_patch_pil)\n",
        "\n",
        "            # Convertir de vuelta a numpy\n",
        "            hr_patch = np.array(hr_patch_pil).astype(np.float32) / 255.0\n",
        "            lr_patch = np.array(lr_patch_pil).astype(np.float32) / 255.0\n",
        "\n",
        "            # Convertir a tensores\n",
        "            hr_patch = torch.from_numpy(hr_patch).permute(2, 0, 1)  # [C, H, W]\n",
        "            lr_patch = torch.from_numpy(lr_patch).permute(2, 0, 1)  # [C, H, W]\n",
        "\n",
        "            return lr_patch, hr_patch\n",
        "        else:\n",
        "            # Para evaluación, devolver imagen completa\n",
        "            hr_image = torch.from_numpy(hr_image).permute(2, 0, 1)\n",
        "            lr_image = torch.from_numpy(lr_image).permute(2, 0, 1)\n",
        "            return lr_image, hr_image\n",
        ""
      ],
      "metadata": {
        "id": "OQdtDXbzuKwG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear datasets\n",
        "train_dataset = SuperResolutionDataset(DIV2K_TRAIN_DIR, is_train=True, subset_size=SUBSET_SIZE)\n",
        "valid_dataset = SuperResolutionDataset(DIV2K_VALID_DIR, is_train=False, subset_size=VALID_SUBSET_SIZE)\n",
        "test_dataset = SuperResolutionDataset(SET5_DIR, is_train=False)\n",
        "\n",
        "# Crear dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "PjYyxTKu6DUl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición del modelo SRCNN\n",
        "class SRCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SRCNN, self).__init__()\n",
        "        # Capa 1: Extracción de parches y representación\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, padding=4)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Capa 2: Mapeo no lineal\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=1, padding=0)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Capa 3: Reconstrucción\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=3, kernel_size=5, padding=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu1(self.conv1(x))\n",
        "        out = self.relu2(self.conv2(out))\n",
        "        out = self.conv3(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "5xIjkrFh7Cmz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar modelo, función de pérdida y optimizador\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "model = SRCNN().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)  # Reducir LR cada 30 épocas\n",
        "\n",
        "# Función para entrenar el modelo\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for lr_batch, hr_batch in dataloader:\n",
        "        lr_batch, hr_batch = lr_batch.to(device), hr_batch.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(lr_batch)\n",
        "        loss = criterion(outputs, hr_batch)\n",
        "\n",
        "        # Backward pass y optimización\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "# Función para evaluar el modelo\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    psnr_val = 0\n",
        "    ssim_val = 0\n",
        "    with torch.no_grad():\n",
        "        for lr_batch, hr_batch in dataloader:\n",
        "            lr_batch, hr_batch = lr_batch.to(device), hr_batch.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(lr_batch)\n",
        "            loss = criterion(outputs, hr_batch)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # Calcular PSNR y SSIM\n",
        "            output_np = outputs.squeeze(0).permute(1, 2, 0).cpu().numpy().clip(0, 1)\n",
        "            target_np = hr_batch.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "            psnr_val += psnr(target_np, output_np, data_range=1.0)\n",
        "            ssim_val += ssim(target_np, output_np,\n",
        "                             data_range=1.0,\n",
        "                             win_size=3,  # Tamaño de ventana más pequeño (3x3)\n",
        "                             channel_axis=2)  # El eje 2 corresponde a los canales RGB\n",
        "\n",
        "    return epoch_loss / len(dataloader), psnr_val / len(dataloader), ssim_val / len(dataloader)\n",
        "\n",
        "# Función para guardar imágenes de ejemplo\n",
        "def save_example(model, dataloader, epoch, device, save_dir='./results'):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for lr_batch, hr_batch in dataloader:\n",
        "            lr_batch, hr_batch = lr_batch.to(device), hr_batch.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            sr_batch = model(lr_batch)\n",
        "\n",
        "            # Convertir a numpy para visualización\n",
        "            lr_img = lr_batch[0].permute(1, 2, 0).cpu().numpy().clip(0, 1)\n",
        "            hr_img = hr_batch[0].permute(1, 2, 0).cpu().numpy()\n",
        "            sr_img = sr_batch[0].permute(1, 2, 0).cpu().numpy().clip(0, 1)\n",
        "\n",
        "            # Calcular PSNR y SSIM\n",
        "            psnr_val = psnr(hr_img, sr_img, data_range=1.0)\n",
        "            ssim_val = ssim(hr_img, sr_img,\n",
        "                           data_range=1.0,\n",
        "                           win_size=3,  # Tamaño de ventana más pequeño\n",
        "                           channel_axis=2)  # El eje 2 corresponde a los canales RGB\n",
        "\n",
        "            # Crear figura\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "            axes[0].imshow(lr_img)\n",
        "            axes[0].set_title('LR Input')\n",
        "            axes[0].axis('off')\n",
        "\n",
        "            axes[1].imshow(sr_img)\n",
        "            axes[1].set_title(f'SR Output (PSNR: {psnr_val:.2f}, SSIM: {ssim_val:.4f})')\n",
        "            axes[1].axis('off')\n",
        "\n",
        "            axes[2].imshow(hr_img)\n",
        "            axes[2].set_title('HR Ground Truth')\n",
        "            axes[2].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'{save_dir}/epoch_{epoch}.png')\n",
        "            plt.close()\n",
        "\n",
        "            break  # Solo guardar una imagen\n",
        "\n",
        "# Entrenamiento principal\n",
        "def train_model(model, train_loader, valid_loader, test_loader, criterion, optimizer, scheduler,\n",
        "                num_epochs=100, device='cpu', save_dir='./checkpoints'):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    best_psnr = 0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_psnrs = []\n",
        "    val_ssims = []\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Entrenamiento\n",
        "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Validación\n",
        "        val_loss, val_psnr, val_ssim = evaluate(model, valid_loader, criterion, device)\n",
        "        val_losses.append(val_loss)\n",
        "        val_psnrs.append(val_psnr)\n",
        "        val_ssims.append(val_ssim)\n",
        "\n",
        "        # Actualizar learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        # Guardar el mejor modelo\n",
        "        if val_psnr > best_psnr:\n",
        "            best_psnr = val_psnr\n",
        "            torch.save(model.state_dict(), f'{save_dir}/best_model.pth')\n",
        "            print(f\"Epoch {epoch}: Mejor modelo guardado con PSNR {best_psnr:.2f}\")\n",
        "\n",
        "        # Guardar checkpoint cada 10 épocas\n",
        "        if epoch % 10 == 0:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'best_psnr': best_psnr\n",
        "            }, f'{save_dir}/checkpoint_epoch_{epoch}.pth')\n",
        "\n",
        "        # Guardar imagen de ejemplo cada 10 épocas\n",
        "        if epoch % 10 == 0:\n",
        "            save_example(model, test_loader, epoch, device)\n",
        "\n",
        "        # Imprimir estadísticas\n",
        "        time_taken = time.time() - start_time\n",
        "        print(f\"Época {epoch}/{num_epochs} - Tiempo: {time_taken:.2f}s - Train Loss: {train_loss:.6f} - \"\n",
        "              f\"Val Loss: {val_loss:.6f} - Val PSNR: {val_psnr:.2f} - Val SSIM: {val_ssim:.4f}\")\n",
        "\n",
        "    # Evaluar en el conjunto de prueba\n",
        "    test_loss, test_psnr, test_ssim = evaluate(model, test_loader, criterion, device)\n",
        "    print(f\"Resultados finales en test - Loss: {test_loss:.6f} - PSNR: {test_psnr:.2f} - SSIM: {test_ssim:.4f}\")\n",
        "\n",
        "    # Guardar gráficas de entrenamiento\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Val Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss vs. Epoch')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(val_psnrs, label='Val PSNR')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('PSNR (dB)')\n",
        "    plt.legend()\n",
        "    plt.title('PSNR vs. Epoch')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(val_ssims, label='Val SSIM')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('SSIM')\n",
        "    plt.legend()\n",
        "    plt.title('SSIM vs. Epoch')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{save_dir}/training_curves.png')\n",
        "    plt.close()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR3rKGdyupY0",
        "outputId": "d32520a9-5ff0-4e1d-feaa-2453d349f659"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 20\n",
        "SAVE_DIR = './srcnn_checkpoints'\n",
        "\n",
        "# Entrenar modelo\n",
        "trained_model = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    valid_loader=valid_loader,\n",
        "    test_loader=test_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=device,\n",
        "    save_dir=SAVE_DIR\n",
        ")\n",
        "\n",
        "# Guardar modelo final\n",
        "torch.save(trained_model.state_dict(), f'{SAVE_DIR}/final_model.pth')\n",
        "print(f\"Modelo final guardado en {SAVE_DIR}/final_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "i-60sTMWuuHJ",
        "outputId": "25ec8c5b-266c-423a-d766-9c1c85fea497"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Mejor modelo guardado con PSNR 22.81\n",
            "Época 1/20 - Tiempo: 200.74s - Train Loss: 0.032641 - Val Loss: 0.006277 - Val PSNR: 22.81 - Val SSIM: 0.6972\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-da3fa37d6eb8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Entrenar modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m trained_model = train_model(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-a0a0d79a7616>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, valid_loader, test_loader, criterion, optimizer, scheduler, num_epochs, device, save_dir)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# Entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-a0a0d79a7616>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlr_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mlr_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-24fb60667655>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Cargar imagen HR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mhr_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mhr_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhr_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convertir a RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mhr_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhr_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m  \u001b[0;31m# Normalizar a [0,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}